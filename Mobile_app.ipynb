{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сборный проект-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вы работаете в стартапе, который продаёт продукты питания. Нужно разобраться, как ведут себя пользователи вашего мобильного приложения.\n",
    "\n",
    "Изучите воронку продаж. Узнайте, как пользователи доходят до покупки. Сколько пользователей доходит до покупки, а сколько — «застревает» на предыдущих шагах? На каких именно?\n",
    "\n",
    "После этого исследуйте результаты A/B-эксперимента. Дизайнеры захотели поменять шрифты во всём приложении, а менеджеры испугались, что пользователям будет непривычно. Договорились принять решение по результатам A/B-теста. Для него пользователей разбили на 3 группы: 2 контрольные со старыми шрифтами и одну экспериментальную — с новыми. Выясните, какой шрифт лучше.\n",
    "\n",
    "В случае общей аналитики и A/B-эксперимента работайте с одними и теми же данными. В реальных проектах всегда идут эксперименты. Аналитики исследуют качество работы приложения по общим данным, не учитывая принадлежность пользователей к экспериментам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1. Откройте файл с данными и изучите общую информацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from scipy import stats as st\n",
    "import numpy as np\n",
    "import statsmodels.stats.api as sms\n",
    "import math as mth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /datasets/logs_exp.csv does not exist: '/datasets/logs_exp.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3b04693f2966>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/datasets/logs_exp.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File /datasets/logs_exp.csv does not exist: '/datasets/logs_exp.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/logs_exp.csv', sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первоначальном виде данные были склеяны.Был добавлен разделитель \"\\t\". Теперь подготовим данные к анализу, займемся их предобработкой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблица df. Значения наименования столбцов:\n",
    "\n",
    "    1) EventName - название события\n",
    "    2) DeviceIDHash - уникальный идентификатор пользователя\n",
    "    3) EventTimestamp - время события\n",
    "    4) ExpId - номер эксперимента: 246 и 247 — контрольные группы, а 248 — экспериментальная"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2. Подготовьте данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заменим названия столбцов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['event', 'user_id', 'event_time', 'exp_num']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проверим пропуски и типы данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проверим пропуски, дубликаты и типы данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков не обнаружено"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на дубликаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.loc[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, строчки не полностью совпадают, поэтому удалять их не нужно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем время в формат datetime64[ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['event_time'] = pd.to_datetime(df['event_time'], unit='s')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим столбец с датами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['event_date'] = df['event_time'].dt.strftime('%Y-%m-%d')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И преобразуем в формат datetime64[ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['event_date'] = df['event_date'].astype('datetime64[ns]')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Итак, данные готовы для дальнейшего анализа. Была проведена их полная предобработка. Были заменены форматы на релевантные, добавлены столбцы с датой и временем, проверены дубликаты и наличие нулей в данных. Можно проверять данные дальше.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 3. Изучите и проверьте данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Сколько событий в логе?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['event'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество уникальных событий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['event'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Сколько пользователей в логе?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Сколько в среднем событий приходится на пользователя?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['event'].count() / df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Данными за какой период вы располагаете? Найдите максимальную и минимальную дату. Постройте гистограмму по дате и времени. Можно ли быть уверенным, что у вас одинаково полные данные за весь период? Технически в логи новых дней по некоторым пользователям могут «доезжать» события из прошлого — это может «перекашивать данные». Определите, с какого момента данные полные и отбросьте более старые. Данными за какой период времени вы располагаете на самом деле?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['event_time'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Располагаем данными с 2019-07-25 по 2019-08-07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.groupby([df['event_date']]).count().plot(kind=\"bar\", y = 'event')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по распределению частот, до 1 августа 2019 года данные были неполные. Целесообразно для проведения дальнейшего анализа сделать срез по этой дате, поскольку фактически мы обладаем данными с этого момента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_df = df.query('event_date >= \"2019-08-01\"').reset_index(drop=True)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Много ли событий и пользователей вы потеряли, отбросив старые данные?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deleted_df = 1 - len(new_df) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Удалили {:.1%} данных'.format(deleted_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['event'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = ((df['event'].count() - new_df['event'].count())/df['event'].count())\n",
    "print('Событий потеряли:','{:.2%}'.format(events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = ((df['user_id'].nunique() - new_df['user_id'].nunique())/df['user_id'].nunique())\n",
    "print('Пользователей потеряли:','{:.2%}'.format(users))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Проверьте, что у вас есть пользователи из всех трёх экспериментальных групп."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['exp_num'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Итак, 1.16% событий и 0.23% пользователей были потеряны в результате среза. Потери незначительны.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделим данные в отдельные датафреймы разбитые по событиям:\n",
    "tut_df = new_df[new_df['event']=='Tutorial']\n",
    "main_df = new_df[new_df['event']=='MainScreenAppear']\n",
    "offer_df = new_df[new_df['event']=='OffersScreenAppear']\n",
    "cart_df = new_df[new_df['event']=='CartScreenAppear']\n",
    "payment_df = new_df[new_df['event']=='PaymentScreenSuccessful']\n",
    "offer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Найдём тех пользователей, чьи id присутствуют в предыдущих этапах воронки:\n",
    "step1 = main_df[~main_df['user_id'].isin(tut_df)]\n",
    "step2 = offer_df[~(offer_df['user_id'].isin(main_df) & offer_df['user_id'].isin(tut_df))]\n",
    "step3 = cart_df[~(cart_df['user_id'].isin(main_df) & cart_df['user_id'].isin(offer_df) & cart_df['user_id'].isin(tut_df))]\n",
    "step4 = payment_df[~(\n",
    "    payment_df['user_id'].isin(tut_df) &\n",
    "    payment_df['user_id'].isin(main_df) & \n",
    "    payment_df['user_id'].isin(offer_df) & \n",
    "    payment_df['user_id'].isin(cart_df))]\n",
    "step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Из получившихся датафреймов соберём \"настоящую\" воронку:\n",
    "data_clean_funnel = pd.concat([tut_df, step1, step2, step3, step4])\n",
    "data_clean_funnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сгруппируем чтобы посмотреть сколько пользователей прошло совершили все шаги:\n",
    "data_clean_funnel_real = data_clean_funnel.groupby(['event','exp_num']).agg({'user_id':'nunique'}).reset_index().sort_values(['exp_num', 'user_id'], ascending=False)\n",
    "data_clean_funnel_real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_funnel_real = data_clean_funnel_real.query('event != \"Tutorial\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Соберём data_clean_funnel_real в табличный вид:\n",
    "data_clean_funnel_real_pivot = pd.pivot_table(data_clean_funnel_real, \n",
    "               index='event',\n",
    "               columns='exp_num', \n",
    "               values='user_id').sort_values(246,ascending=False)\n",
    "data_clean_funnel_real_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим что в фрейме имеются пользователи из всех трех групп."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 4. Изучите воронку событий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Посмотрите, какие события есть в логах, как часто они встречаются. Отсортируйте события по частоте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.groupby('event')['event'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В логах имеются следующие события: \"Главный экран\",\"Предложения\", \"Положили в корзину\", \"Оплатили\", \"Прошли обучение\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Посчитайте, сколько пользователей совершали каждое из этих событий. Отсортируйте события по числу пользователей. Посчитайте долю пользователей, которые хоть раз совершали событие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = new_df.pivot_table(index='event', values='user_id', aggfunc='nunique').sort_values('user_id', ascending=False)\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df['count_id'] = new_df.groupby('event')['event'].count().sort_values(ascending=False)\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df['part']=pivot_df['user_id']/new_df['event'].count()*100\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Предположите, в каком порядке происходят события. Все ли они выстраиваются в последовательную цепочку? Их не нужно учитывать при расчёте воронки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предполагаю, что события идут в следующем порядке: Tutorial → MainScreenAppear → OffersScreenAppear → CartScreenAppear → PaymentScreenSuccessful.\n",
    "Логично предположить, что Tutorial происходит в начале, но не все предпочитают его проходить, поэтому его исключим из воронки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = pivot_df.query('user_id != 840')\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- По воронке событий посчитайте, какая доля пользователей проходит на следующий шаг воронки (от числа пользователей на предыдущем). То есть для последовательности событий A → B → C, посчитайте отношение числа пользователей с событием B к количеству пользователей с событием A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_step = pivot_df['user_id'][1] / pivot_df['user_id'][0]\n",
    "second_step = pivot_df['user_id'][2] / pivot_df['user_id'][1]\n",
    "third_step = pivot_df['user_id'][3] / pivot_df['user_id'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Конверсия из MainScreenAppear в OffersScreenAppear:', '{:.2%}'.format(first_step))\n",
    "print ('Конверсия из OffersScreenAppear в CartScreenAppear:', '{:.2%}'.format(second_step))\n",
    "print ('Конверсия из CartScreenAppear в PaymentScreenSuccessful:', '{:.2%}'.format(third_step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всю ту же информацию можно поглядеть на визуализации воронки, которую я расположу чуть ниже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переименуем колонки и добавим колонку с суммарным количеством пользователей контрольных групп"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean_funnel_real_pivot.columns = ['A1', 'A2', 'B']\n",
    "data_clean_funnel_real_pivot['mixed_AA'] = data_clean_funnel_real_pivot['A1'] + data_clean_funnel_real_pivot['A2']\n",
    "final_df = data_clean_funnel_real_pivot[['A1', 'A2', 'mixed_AA', 'B']]\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from plotly import graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Funnel(\n",
    "    name = 'Воронка группы А1',\n",
    "    y = [\"Главный экран\",\"Предложения\", \"Положили в корзину\", \"Оплатили\"],\n",
    "    x = final_df['A1'],\n",
    "    textinfo = \"value+percent initial\"))\n",
    "\n",
    "fig.add_trace(go.Funnel(\n",
    "    name = 'Воронка группы А2',\n",
    "    orientation = \"h\",\n",
    "    y = [\"Главный экран\",\"Предложения\", \"Положили в корзину\", \"Оплатили\"],\n",
    "    x = final_df['A2'],\n",
    "    textposition = \"inside\",\n",
    "    textinfo = \"value+percent initial\"))\n",
    "\n",
    "fig.add_trace(go.Funnel(\n",
    "    name = 'Воронка группы B',\n",
    "    orientation = \"h\",\n",
    "    y = [\"Главный экран\",\"Предложения\", \"Положили в корзину\", \"Оплатили\"],\n",
    "    x = final_df['B'],\n",
    "    textposition = \"inside\",\n",
    "    textinfo = \"value+percent initial\"))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "мы получили воронку событий в разрезе трех групп: А1, А2, и B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- На каком шаге теряете больше всего пользователей?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Невооруженным глазом видно что большая часть пользователей теряется на самом первом шаге, при переходе с главного экрана к экрану с товарами. На этом шаге мы терям 40% пользователей. Около 20% пользователей уходят на втором этапе - этапе перехода от товаров к корзине с покупками. Ну и самые незначительные потери мы видим на этапе перехода от корзины к оплате, тут мы теряем 5% пользователей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Какая доля пользователей доходит от первого события до оплаты?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_of_total = pivot_df['user_id'][3] / pivot_df['user_id'][0]\n",
    "print ('Итоговая конверсия из посетителя в покупателя:', '{:.2%}'.format(part_of_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Во всем датафрейме чуть меньше половины доходит до оплаты, а теряется больше всего пользователей после первого шага. Возможно это связано с тем, что пользователи случайно оказались на главном экране.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 5. Изучите результаты эксперимента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Сколько пользователей в каждой экспериментальной группе?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = new_df.pivot_table(index='exp_num', values='user_id', aggfunc='nunique')\n",
    "groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чисто визуально количество униклаьных пользователей в группе практически не отличается. Нужно будет знать, статистически значимы ли отличия между этими группами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Есть 2 контрольные группы для А/А-эксперимента, чтобы проверить корректность всех механизмов и расчётов. Проверьте, находят ли статистические критерии разницу между выборками 246 и 247."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем снова конечную воронку, чтобы для расчета Z статистики брать оттуда значения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подставим теперь значения для групп А1 и А2 для проверки равенства долей. Предположим, что доли пользователей, которые совершают события у групп А1 и А2 равны. Альтернативная гипотеза будет утверждать, что разница между долями значима."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "purchases = np.array([1200, 1158])\n",
    "leads = np.array([2484, 2513])\n",
    "\n",
    "# пропорция успехов в первой группе:\n",
    "p1 = purchases[0] / leads[0]\n",
    "\n",
    "# пропорция успехов во второй группе:\n",
    "p2 = purchases[1] / leads[1]\n",
    "\n",
    "# пропорция успехов в комбинированном датасете:\n",
    "p_combined = (purchases[0] + purchases[1]) / (leads[0] + leads[1])\n",
    "\n",
    "# разница пропорций в датасетах\n",
    "difference = p1 - p2\n",
    "\n",
    "# считаем статистику в ст.отклонениях стандартного нормального распределения\n",
    "z_value = difference / mth.sqrt(p_combined * (1 - p_combined) * (1 / leads[0] + 1 / leads[1]))\n",
    "\n",
    "# задаем стандартное нормальное распределение (среднее 0, ст.отклонение 1)\n",
    "distr = st.norm(0, 1)\n",
    "\n",
    "p_value = (1 - distr.cdf(abs(z_value))) * 2\n",
    "\n",
    "print('p-значение: ', p_value)\n",
    "\n",
    "if (p_value < alpha):\n",
    "    print(\"Отвергаем нулевую гипотезу: между долями есть значимая разница\")\n",
    "else:\n",
    "    print(\"Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, статистика показала, что доли групп А1 и А2 нельзя считать разными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Выберите самое популярное событие. Посчитайте число пользователей, совершивших это событие в каждой из контрольных групп. Посчитайте долю пользователей, совершивших это событие. Проверьте, будет ли отличие между группами статистически достоверным. Проделайте то же самое для всех других событий (удобно обернуть проверку в отдельную функцию). Можно ли сказать, что разбиение на группы работает корректно?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самым популярным событием у пользователей является просмотр главного экрана."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(data):\n",
    "    for k in range(len(data)-3):\n",
    "        print('')\n",
    "        print('Для', k+1,'контрольной группы и контрольной группы 2')\n",
    "        print('--------------------------------------')\n",
    "        for i in range(len(data)-1): \n",
    "            \n",
    "            alpha = .05 \n",
    "            \n",
    "            successes = np.array(list(data.iloc[i+1,[k,1]]))\n",
    "            trials = np.array(list(data.iloc[i,[k,1]]))\n",
    "            \n",
    "            p1 = successes[0]/trials[0]\n",
    "            p2 = successes[1]/trials[1]\n",
    "            \n",
    "            p_combined = (successes[0] + successes[1]) / (trials[0] + trials[1])\n",
    "            \n",
    "            difference = p1 - p2\n",
    "            \n",
    "            z_value = difference / mth.sqrt(p_combined * (1 - p_combined) * (1/trials[0] + 1/trials[1]))\n",
    "            distr = st.norm(0, 1) \n",
    "            \n",
    "            p_value = (1 - distr.cdf(abs(z_value))) * 2\n",
    "            \n",
    "            print('p-значение: ', p_value)\n",
    "            if (p_value < alpha):\n",
    "                print(\"Отвергаем нулевую гипотезу: между долями есть значимая разница\")\n",
    "            else:\n",
    "                print(\"Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По полученным данным видно, что для контрольных групп А1 и А2 нет статистически значимых различий между долями, значит можно утверждать, что разбиение на контрольные группы работает корректно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитаем число пользователей, совершивших это событие в каждой из контрольных групп."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Число пользователей, совершивших событие в группе А1:',final_df.iloc[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Число пользователей, совершивших событие в группе А2:',final_df.iloc[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитаем долю пользователей, совершивших это событие в группах А1 и А2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_a1 = final_df.iloc[0][0]/pivot_df['user_id'][0]\n",
    "print('{:.2%}'.format(part_a1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_a2 = final_df.iloc[0][1]/pivot_df['user_id'][0]\n",
    "print('{:.2%}'.format(part_a2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Доли пользователей, совершивших самое популярное событие, в контрольных группах А1 и А2 не имеют статистически значимых различий."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Аналогично поступите с группой с изменённым шрифтом. Сравните результаты с каждой из контрольных групп в отдельности по каждому событию. Сравните результаты с объединённой контрольной группой. Какие выводы из эксперимента можно сделать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этих целей используем функцию, которой нужно передать конечный датафрейм с воронкой. В теле функции зададим два цикла, которые построчно бы сравнивали поочередно колонку группы А1 с колонкой группы B, затем колонку группы А2 с колонкой группы B и, наконец, колонку сборной группы А1 и А2 с колонкой группы B. Аналогично, в качестве нулевой гипотезы зададим равенство долей пользователей в двух сравниваемых группах, а качестве альтернативной гипотезы – разница между долями пользователей, совершающих события, в двух разных группах значимо различаются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_1(data):\n",
    "    for k in range(len(data)-1):\n",
    "        print('')\n",
    "        print('Для', k+1,'контрольной группы и тестовой')\n",
    "        print('--------------------------------------')\n",
    "        for i in range(len(data)-1):\n",
    "            alpha = .05 \n",
    "            successes = np.array(list(data.iloc[i+1,[k,3]]))\n",
    "            trials = np.array(list(data.iloc[i,[k,3]]))\n",
    "            p1 = successes[0]/trials[0]\n",
    "            p2 = successes[1]/trials[1]\n",
    "            p_combined = (successes[0] + successes[1]) / (trials[0] + trials[1])\n",
    "            difference = p1 - p2\n",
    "            z_value = difference / mth.sqrt(p_combined * (1 - p_combined) * (1/trials[0] + 1/trials[1]))\n",
    "            distr = st.norm(0, 1) \n",
    "            p_value = (1 - distr.cdf(abs(z_value))) * 2\n",
    "            print('p-значение: ', p_value)\n",
    "            if (p_value < alpha):\n",
    "                print(\"Отвергаем нулевую гипотезу: между долями есть значимая разница\")\n",
    "            else:\n",
    "                print(\"Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_1(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Таким образом, между контрольной группой А2 и экспериментальной группой B на 3 шаге воронки (при переходе от корзины к оплате) есть небольшая статистическая разница в результате чего отвергается нулевая гипотеза. При этом, на всех остальных шагах нет статистически значимых событий между шагами. Ввиду этого, следует сделать вывод о том, что такими небольшими статистически значимыми различиями в тесте можно пренебречь. Таким образом, нет необходимости в введении нового шрифта для пользователей.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Какой уровень значимости вы выбрали при проверке статистических гипотез выше? Посчитайте, сколько проверок статистических гипотез вы сделали. При уровне значимости 0.1 каждый десятый раз можно получать ложный результат. Какой уровень значимости стоит применить? Если вы хотите изменить его, проделайте предыдущие пункты и проверьте свои выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как у нас происходило 3 сравнения, то критический уровень статистической значимости 0,05 был скорректирован с помощью порпавки Бонферрони:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_2(data):\n",
    "    for k in range(len(data)-1):\n",
    "        print('')\n",
    "        print('Для', k+1,'контрольной группы и тестовой')\n",
    "        print('--------------------------------------')\n",
    "        for i in range(len(data)-1):\n",
    "            alpha = .05\n",
    "            bonferroni_alpha = alpha / 3\n",
    "            successes = np.array(list(data.iloc[i+1,[k,3]]))\n",
    "            trials = np.array(list(data.iloc[i,[k,3]]))\n",
    "            p1 = successes[0]/trials[0]\n",
    "            p2 = successes[1]/trials[1]\n",
    "            p_combined = (successes[0] + successes[1]) / (trials[0] + trials[1])\n",
    "            difference = p1 - p2\n",
    "            z_value = difference / mth.sqrt(p_combined * (1 - p_combined) * (1/trials[0] + 1/trials[1]))\n",
    "            distr = st.norm(0, 1) \n",
    "            p_value = (1 - distr.cdf(abs(z_value))) * 2\n",
    "            print('p-значение: ', p_value)\n",
    "            if (p_value < bonferroni_alpha):\n",
    "                print(\"Отвергаем нулевую гипотезу: между долями есть значимая разница\")\n",
    "            else:\n",
    "                print(\"Не получилось отвергнуть нулевую гипотезу, нет оснований считать доли разными\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_2(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Таким образом, даже при смене статистически значимого критерия альфа, на каждом шагу для каждой группы мы получили почти такой же результат по принятию или отвержению нулевой гипотезы. Это означает, что наши данные верные и судя по A/B тесту нет необходимости во введении нового шрифта в приложении.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общие выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После произведеноого анализа и проведения экспериментов можно сделать следующие выводы:\n",
    " - В среднем на одного пользователя приходится 32,3 события. \n",
    " - Видно что большая часть пользователей теряется на самом первом шаге, при переходе с главного экрана к экрану с товарами. На этом шаге мы терям 40% пользователей. Около 20% пользователей уходят на втором этапе - этапе перехода от товаров к корзине с покупками. Ну и самые незначительные потери мы видим на этапе перехода от корзины к оплате, тут мы теряем 5% пользователей.\n",
    " - Итоговая конверсия из посетителя в покупателя: 47.70%\n",
    " - Обучающим разделом (tutorial), который должен по логике находиться на самом верху воронки, воспользовалось меньше всего пользователей. Скорее всего большинство его просто пропускало.\n",
    " - Нет основание считать, что показатели экспериментальной группы B с изменённым шрифтом отличаются от групп с первоначальным вариантом шрифта по всем событиям. Из этого следует, что внедрение нового типа шрифта протестированного на группе B не приведет к увеличению показателей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly import graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Funnel(\n",
    "    name = 'Воронка группы А1',\n",
    "    y = [\"Главный экран\",\"Предложения\", \"Положили в корзину\", \"Оплатили\"],\n",
    "    x = final_df['A1'],\n",
    "    textinfo = \"value+percent initial\"))\n",
    "\n",
    "fig.add_trace(go.Funnel(\n",
    "    name = 'Воронка группы А2',\n",
    "    orientation = \"h\",\n",
    "    y = [\"Главный экран\",\"Предложения\", \"Положили в корзину\", \"Оплатили\"],\n",
    "    x = final_df['A2'],\n",
    "    textposition = \"inside\",\n",
    "    textinfo = \"value+percent initial\"))\n",
    "\n",
    "fig.add_trace(go.Funnel(\n",
    "    name = 'Воронка группы B',\n",
    "    orientation = \"h\",\n",
    "    y = [\"Главный экран\",\"Предложения\", \"Положили в корзину\", \"Оплатили\"],\n",
    "    x = final_df['B'],\n",
    "    textposition = \"inside\",\n",
    "    textinfo = \"value+percent initial\"))\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
